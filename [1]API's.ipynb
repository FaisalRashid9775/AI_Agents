{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXbzhVFRF9z8MIqKaIunVv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalRashid9775/AI_Agents/blob/main/%5B1%5DAPI's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API Introduction & OpenAI API's**   \n",
        "\n",
        "## **API Introduction: **   \n",
        "1. What is API?   \n",
        "\n",
        "(Application Programming Interface).\n",
        "Set of rules that let talk one software to another.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Same like a restaurant.  You order a waiter and waiter tell to chefs what to cook. Chefs ready your dish and transfer to you through waiter. So waiter is work like a API.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In 2022 most provider launched their LLM and allow public to access their LLM through their API. But there is no standard for accessing LLM. Each LLM provider making their own API. Langchain allow user to access mostly LLM through their standard (same code for each LLM). You will use same method for API calling and backend handling was the responsibility of Langchain.\n",
        "\n",
        "\n",
        "\n",
        "After it, OPENAI launch a standard “Chat completions API” which become standard and mostly LLM provider follow it. OpenAI have launch two API's\n",
        "\n",
        "1. Chat Completions API :  These API’s are stateless. They can not manage history. So each time you have to send full details (History) to LLM.\n",
        "2. Responsive API : These are statful API plus they also have some build-in tools\n",
        "\n",
        "*\tWeb search\n",
        "*\tFile retrieval\n",
        "* Code interpreter\n",
        "* Image Generation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pS8LLXE9WJ6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgFZSwRSWJFZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API Calling in Python**"
      ],
      "metadata": {
        "id": "ozusTJXbax7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests , pprint\n",
        "Resp = requests.get('URL')\n",
        "Resp.raise_for_status()\n",
        "Weather = Resp.json()\n",
        "pprint.pp(Weather)\n"
      ],
      "metadata": {
        "id": "NiGB0G5CZd4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI Chat Completions API**"
      ],
      "metadata": {
        "id": "l3xGmnbIa7T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "nPDzG8Txa6t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "api_key= userdata.get('GOOGLE_API_KEY')\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "reponse  = client.chat.completions.create(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    messages = [\n",
        "\n",
        "        {'role': 'user', 'content': 'Who won the cricket world cup in 1992?'},\n",
        "        ]\n",
        ")\n",
        "print(reponse.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm2KEIoObSTo",
        "outputId": "7cdda54d-90ec-491e-bf88-3825bb0d8658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Pakistan** won the Cricket World Cup in 1992, defeating England in the final.\n"
          ]
        }
      ]
    }
  ]
}