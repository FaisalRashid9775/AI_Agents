{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5azvL/lC2jyoAmw8oW7Ss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalRashid9775/AI_Agents/blob/main/%5B6%5DLocal_Context%26Dynamics_Instruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local **Context**\n",
        "\n",
        "Local Context is helpful while managing personal seesion for each user.  We can directly pass context to tool without LLM. It available throughout the loop in all tools. You can pass a object in this context. Because **In python everything is object** so we can use list, int. str anything in context.\n",
        "\n",
        "Step for passing context :\n",
        "\n",
        "\n",
        "1. Create object using data classes .\n",
        "2. Pass this object in Runner like context = your_obj\n",
        "3. This will be available in tool with RunContextWrapper class\n",
        "4. Context : RunContextWrapper\n",
        "\n"
      ],
      "metadata": {
        "id": "5E2lkXyxXNNO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC8oW5auLFCb",
        "outputId": "d749011e-1f22-4ecb-cca7-650530b7f708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/185.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/946.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m942.1/946.9 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.9/946.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,OpenAIChatCompletionsModel,AsyncOpenAI,set_tracing_disabled, function_tool, RunContextWrapper, ModelSettings\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key= userdata.get('GOOGLE_API_KEY')\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class user :\n",
        "  name:str\n",
        "  interest:str\n",
        "  location :str\n",
        "\n",
        "client : AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "model : OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    openai_client=client\n",
        ")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "@function_tool()\n",
        "async def userInfo(info :RunContextWrapper[user] ):\n",
        "  print('tool user info calling')\n",
        "  return f' user name is {info.context.name} and he is interested is {info.context.interest} and his location is {info.context.location}'\n",
        "\n",
        "user1= user('Ahmed','CS','Karachi')\n",
        "user2= user('Ali','IOT','New York')\n",
        "\n",
        "math_agent = Agent(\n",
        "    name='math-agent',\n",
        "    instructions='''You are helpful assistant.Call userInfo and get name of person and interest.\n",
        "     Start with saying Hello with name. Always resposne according to his interest and location.\n",
        "     Do not always tell user their information ''',\n",
        "    model=model,\n",
        "    model_settings=ModelSettings(temperature=0.5),\n",
        "    tools=[userInfo],\n",
        "    )\n",
        "# local context willl be in\n",
        "reponse  = Runner.run_sync(math_agent,'Is there is any univercity in my city', context=user1)\n",
        "print(reponse.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOJFwxp7MxSp",
        "outputId": "a35cf47c-44d8-4bba-a3de-4cdd9f9473ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tool user info calling\n",
            "Hello Ahmed!\n",
            "\n",
            "Yes, there are many universities in Karachi. Since you're interested in Computer Science, some popular options include:\n",
            "\n",
            "*   **NED University of Engineering & Technology:** Known for its strong engineering and CS programs.\n",
            "*   **FAST-NUCES (National University of Computer and Emerging Sciences):** Highly regarded for its Computer Science and IT degrees.\n",
            "*   **University of Karachi:** Offers a range of CS programs.\n",
            "*   **Institute of Business Administration (IBA):** While primarily a business school, it also has a reputable Computer Science department.\n",
            "\n",
            "Would you like me to provide more details about any of these, or perhaps help you find others that might align with your specific interests within CS?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dynamic Instruction**\n",
        "\n",
        "You can pass customize instruction for each user by these steps\n",
        "\n",
        "1. Make a function for dynamics instruction. This function took context and agent.\n",
        "2. Call this function in agent instructions"
      ],
      "metadata": {
        "id": "JIsZhfo8RV1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,OpenAIChatCompletionsModel,AsyncOpenAI,set_tracing_disabled, function_tool, RunContextWrapper, ModelSettings\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key= userdata.get('GOOGLE_API_KEY')\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class user :\n",
        "  name:str\n",
        "  interest:str\n",
        "  location :str\n",
        "\n",
        "client : AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "model : OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    openai_client=client\n",
        ")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def prompt(context :RunContextWrapper[user],agent : Agent[user]) ->str:\n",
        "  print(f'Name : {context.context.name},,, Agent : {agent.name} ')\n",
        "  return f'Your name is  {agent.name}. Help user {context.context.name}. '\n",
        "\n",
        "user1= user('Ahmed','IT','Karachi')\n",
        "user2= user('Ali','IOT','New York')\n",
        "\n",
        "math_agent = Agent(\n",
        "    name='math-agent',\n",
        "    instructions=prompt,\n",
        "    model=model,\n",
        "    model_settings=ModelSettings(temperature=0.5),\n",
        "    )\n",
        "reponse  = Runner.run_sync(math_agent,'Tell me user name', context=user1)\n",
        "print(reponse.final_output)"
      ],
      "metadata": {
        "id": "pRVyJHLZRVdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c0fe22-f6ae-46af-b76d-cd69b18ac27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name : Ahmed,,, Agent : math-agent \n",
            "Your name is Ahmed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ieAe1JHtbmk2"
      }
    }
  ]
}