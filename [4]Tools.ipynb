{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO42WGyVvlLq7nJ544P2ymh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalRashid9775/AI_Agents/blob/main/%5B4%5DTools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tools**\n",
        "\n",
        "In earlier we talk about agent have LLM and Tools. LLM do not have real time data. For giving it real time details we provide it tool. Tool is just a python function.\n",
        "\n",
        "\n",
        "Tool calling is when AI decide to use a tool.\n",
        "When LLM have not data it check its tool box and call appropriate tool.\n",
        "\n",
        "\n",
        "We just do two things.\n",
        "\n",
        "1. Make a function with function_tool\n",
        "2. Add tool into agent\n",
        "\n",
        "agent = Agent(name = '',instructions = '',model = '', tools = [tools name])\n",
        "\n",
        "tools take strings so we can add more than 1 tools"
      ],
      "metadata": {
        "id": "MoL8K8ETi-Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_vE8zb5hyI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537deec8-8420-4cab-cd9a-6028428fd36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/185.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.9/946.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Runner, Agent, AsyncOpenAI,set_tracing_disabled,OpenAIChatCompletionsModel,function_tool\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "api_key= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "client : AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "\n",
        "model : OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "set_tracing_disabled(disabled= True)\n",
        "#function_tool decorator convert normal function into a Tool.\n",
        "@function_tool()\n",
        "def add (a:int,b:int) -> int:\n",
        "  print('Tool Add Calling')\n",
        "  return a+b\n",
        "math_agent = Agent(\n",
        "    name='Math-agent',\n",
        "    instructions='You are helpful math agent',\n",
        "    model=model,\n",
        "    tools = [add]  # Adding Tool to a Agent\n",
        "    )\n",
        "result = Runner.run_sync(math_agent,'what is 2+2')\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvxbBwfUpOx8",
        "outputId": "62eaf318-23b8-4fed-a656-a9f5d712696e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Add Calling\n",
            "The sum of 2 and 2 is 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tavily Search Tool**"
      ],
      "metadata": {
        "id": "JUZMlg33tGDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq tavily-python"
      ],
      "metadata": {
        "id": "mQUKX0tfuIQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Runner, Agent, AsyncOpenAI,set_tracing_disabled,OpenAIChatCompletionsModel,function_tool\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "from tavily import TavilyClient\n",
        "api_key= userdata.get('GOOGLE_API_KEY')\n",
        "tavily_api_key = userdata.get('TAVILY_API_KEY')\n",
        "tavily_client = TavilyClient(api_key=tavily_api_key)\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "client : AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "\n",
        "model : OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    openai_client=client\n",
        ")\n",
        "set_tracing_disabled(disabled= True)\n",
        "@function_tool()\n",
        "def search(query:str):\n",
        "  print('search tool calling')\n",
        "  response = tavily_client.search(query)\n",
        "  return response\n",
        "\n",
        "math_agent = Agent(\n",
        "    name='Math-agent',\n",
        "    instructions='You are helpful math agent',\n",
        "    model=model,\n",
        "    tools = [search]  # Adding Tool to a Agent\n",
        "    )\n",
        "result = Runner.run_sync(math_agent,'whats the temperature in Islamabd')\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgbyxJK7pOiV",
        "outputId": "0bbdd989-5865-4c85-c1db-5eb89eff9879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search tool calling\n",
            "The temperature in Islamabad is currently 89°F, with a RealFeel® of 78°F. The high for today is 94°F (32°C).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Page Extraction**"
      ],
      "metadata": {
        "id": "wzo7IQd5wAQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_url(url:str)->str:\n",
        "    print(f\"Reading{url}\")\n",
        "    response =await tavily_client.extract(url)"
      ],
      "metadata": {
        "id": "BEccw0M1wHMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}